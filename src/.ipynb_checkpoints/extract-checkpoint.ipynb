{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen: cannot load any more object with static TLS",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-f84c58339382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home1/bqw/GraphSum/src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_word_piece\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/bqw/GraphSum/src/others/tokenization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/bqw/anaconda3/lib/python3.6/site-packages/pytorch_transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1.1.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasicTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWordpieceTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIGPTTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_transfo_xl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTransfoXLTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransfoXLCorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/bqw/anaconda3/lib/python3.6/site-packages/pytorch_transformers/tokenization_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIGPTTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_gpt2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_transfo_xl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransfoXLTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_xlnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXLNetTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_xlm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXLMTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/bqw/anaconda3/lib/python3.6/site-packages/pytorch_transformers/tokenization_transfo_xl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/bqw/anaconda3/lib/python3.6/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_dl_flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen: cannot load any more object with static TLS"
     ]
    }
   ],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('/home1/bqw/stanford-corenlp-full-2018-10-05')\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.executable\n",
    "sys.path.append('/home1/bqw/GraphSum/src')\n",
    "from others.tokenization import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, no_word_piece=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home1/bqw/nlp_data/nyt_corpus/data/1996/01', '/home1/bqw/nlp_data/nyt_corpus/data/1996/02', '/home1/bqw/nlp_data/nyt_corpus/data/1996/03', '/home1/bqw/nlp_data/nyt_corpus/data/1996/04', '/home1/bqw/nlp_data/nyt_corpus/data/1996/05', '/home1/bqw/nlp_data/nyt_corpus/data/1996/06', '/home1/bqw/nlp_data/nyt_corpus/data/1996/07', '/home1/bqw/nlp_data/nyt_corpus/data/1996/08', '/home1/bqw/nlp_data/nyt_corpus/data/1996/09', '/home1/bqw/nlp_data/nyt_corpus/data/1996/10', '/home1/bqw/nlp_data/nyt_corpus/data/1996/11', '/home1/bqw/nlp_data/nyt_corpus/data/1996/12']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "glob.glob(os.path.join('/home1/bqw/nlp_data/nyt_corpus/data', '1996/'))\n",
    "os.listdir('/home1/bqw/nlp_data/nyt_corpus/data/1996')\n",
    "# os.path.join('/home1/bqw/nlp_data/nyt_corpus/data', '2006')\n",
    "month_tarballs=glob.glob(os.path.join('/home1/bqw/nlp_data/nyt_corpus/data', '1996', '*'))\n",
    "\n",
    "month_tarballs = list(filter(lambda x: '.tgz' not in x, month_tarballs))\n",
    "month_tarballs.sort()\n",
    "\n",
    "print(month_tarballs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(os.path.join('/home1/bqw/nlp_data/nyt_corpus/data/1996/01','*'))\n",
    "a=glob.glob(os.path.join('/home1/bqw/nlp_data/nyt_corpus/data/1996/01/24','*'))\n",
    "a.sort()\n",
    "# print(a)\n",
    "# for i in a:\n",
    "#     print(i)\n",
    "# ls *.tgz | xargs -n1 tar -xzvf\n",
    "# import tarfile\n",
    "# with tarfile.open('/home1/bqw/nlp_data/nyt_corpus/data/1996/01/24/0825150.xml', 'r') as f:\n",
    "#     doc = NYTDoc('/home1/bqw/nlp_data/nyt_corpus/data/1996/01/24/0825150.xml')\n",
    "# import codecs\n",
    "# with codecs.open('/home1/bqw/nlp_data/nyt_corpus/data/1996/01/01/0819618.xml','r','utf-8') as f:\n",
    "#     a=[meta.strip() for meta in f]\n",
    "# a[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['469c6ac05092ca5997728c9dfc19f9ab6b936e40', 'f001ec5c4704938247d27a44948eebb37ae98d01', 'e2706dce6cf26bc61b082438188fdb6e130d9e40']\n",
      "['http://web.archive.org/web/20150401100102id_/http://www.cnn.com/2015/04/01/europe/france-germanwings-plane-crash-main/', 'http://web.archive.org/web/20150401123500id_/http://www.cnn.com/2015/04/01/middleeast/palestinians-icc-membership/', 'http://web.archive.org/web/20150401232105id_/http://www.cnn.com/2015/03/31/world/amnesty-2014-death-penalty-report/']\n",
      "['148300', '172101', '61135']\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from os.path import join as pjoin\n",
    "import glob\n",
    "def hashhex(s):\n",
    "    \"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"\n",
    "    h = hashlib.sha1()\n",
    "    h.update(s.encode('utf-8'))\n",
    "    return h.hexdigest()\n",
    "\n",
    "temp=[]\n",
    "init=[]\n",
    "corpus_mapping = {}\n",
    "for line in open(pjoin('/home1/bqw/GraphSum/urls', 'mapping_' + 'test' + '.txt')):\n",
    "    init.append(line.strip())\n",
    "    temp.append(hashhex(line.strip()))\n",
    "corpus_mapping['test'] = {key.strip(): 1 for key in temp}\n",
    "print(temp[:3])\n",
    "print(init[:3])\n",
    "\n",
    "real_store=[]\n",
    "for f in glob.glob(pjoin('/home1/bqw/nlp_data/nyt_token', '*.json')):\n",
    "    real_name = f.split('/')[-1].split('.')[0]\n",
    "    real_store.append(real_name)\n",
    "print(real_store[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen: cannot load any more object with static TLS",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-e88f69436fdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/bqw/anaconda3/lib/python3.6/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_dl_flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen: cannot load any more object with static TLS"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "b=torch.arange(24).view((2,3,4))\n",
    "print(b)\n",
    "print(b[:,2,:])\n",
    "torch.max(b, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"Kosgi Santosh sent an email to Stanford University . He didn't get a reply\"\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "dep=nlp(sentence)\n",
    "for chunk in dep.noun_chunks:\n",
    "    print(chunk.text,'-', chunk.root.text,'-', chunk.root.dep_,'-',\n",
    "            chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import graph and tfidf lda\n",
    "from gensim import corpora, models\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "lda_model_tfidf = models.ldamodel.LdaModel.load('/home1/bqw/sum/sum_topic_10.model')\n",
    "lda_dict = corpora.Dictionary.load('/home1/bqw/sum/topic.dict')\n",
    "tfidf_dict = corpora.Dictionary.load('/home1/bqw/sum/tfidf.mm')\n",
    "rel_map=None\n",
    "neighbor=None\n",
    "graph_dict=None\n",
    "with open('/home1/bqw/nlp_data/rel_map.json', 'r') as f:\n",
    "    rel_map = json.load(f)\n",
    "with open('/home1/bqw/nlp_data/graph_dict.json', 'r') as f:\n",
    "    graph_dict = json.load(f)\n",
    "with open('/home1/bqw/nlp_data/neighbor.json', 'r') as f:\n",
    "    neighbor=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start ------------------------------\n",
    "# start ------------------------------\n",
    "# import spacy and coreference\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Add neural coref to SpaCy's pipe\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "REMAP = {\"-lrb-\": \"(\", \"-rrb-\": \")\", \"-lcb-\": \"{\", \"-rcb-\": \"}\",\n",
    "         \"-lsb-\": \"[\", \"-rsb-\": \"]\", \"``\": '\"', \"''\": '\"',\"`\": \"'\",\n",
    "        \"-LRB-\": \"(\", \"-RRB-\": \")\", \"-LCB-\": \"{\", \"-RCB-\": \"}\",\n",
    "         \"-LSB-\": \"[\", \"-RSB-\": \"]\"}\n",
    "my_re = re.compile(r\"-lsb-|-rrb-|-lcb-|-rcb-|-lsb-|-rsb-|-LSB-|-RRB-|-LCB-|-RCB-|-LSB-|-RSB-|``|''\")\n",
    "\n",
    "def clean(x):\n",
    "    return re.sub(\n",
    "        r\"-LSB-|-rrb-|-lcb-|-rcb-|-lsb-|-rsb-|``|''\",\n",
    "        lambda m: REMAP.get(m.group()), x)\n",
    "\n",
    "test=\"I think the second biggest problem is we 've become selfish . Nobody got that upset about -LSB- Operation -RSB- Fast and Furious .\"\n",
    "re.sub(r\"-lsb-|-rrb-|-lcb-|-rcb-|-lsb-|-rsb-|-LSB-|-RRB-|-LCB-|-RCB-|-LSB-|-RSB-|``|''\",\n",
    "        lambda m: REMAP.get(m.group()), test)\n",
    "# test.replace('-LSB-','[')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sen. Rand Paul and Gov. Chris Christie placed first and second in a straw poll held during this weekend's Northeast Republican Leadership Conference, but Dr. Ben Carson may have stolen the show without being a candidate for anything. He emerged in third place with 11 per cent support, tied with Wisconsin Gov. Scott Walker and former Sen. Rick Santorum. Paul led them by less than four points, with 14.7 per cent support. Christie polled 13 per cent. A 'draft committee' intent on sparking Carson to run for the White House in 2016 raised more than $2.8 million in its first six months of existence. That's more than double what the 'Ready For Hillary' group raised in its initial half-year, even though Hillary Clinton's candidacy seems far more assured than Carson's. Dr. Ben Carson, professor emeritus at the Johns Hopkins School of Medicine, has become a quiet force in the 2016 Republican presidential race without announcing a thing The group angling to persuade Carson to make a White House run brought activists to support him at CPAC, near D.C., in large numbers, but fared even better in a smaller New Hampshire setting without the extra muscle Why they fight: New England Republicans mocked their favorite Democratic villains during the two-day conference in Nashua, N.H. The top two poll slots at the smallish event that concluded Saturday in Nashua, N.H. mirrored those of a statewide Suffolk University/Boston Herald poll released on March 6. Christie and Paul were tied with 12 per cent support each in that earlier poll, a tiny level of backing that shows how wide open the 2016 GOP presidential nomination race is. The top vote-getter, in reality, was 'undecided.' Clinton, by contrast, typically dominates the Democrats' prospective 2016 field, leading all comers by 40 points or more. Carson was not included on the Suffolk pollsters' list. He polled 9 per cent – good enough for another third-place finish – in a straw poll at this month's Conservative Political Action Conference. But Paul dominated and won for the second straight year, with a 31 per cent showing. CPAC is a a much larger gathering dominated by insurgent tea party-aligned activists, which included remarks from Carson. But unlike the hyper-conservative event, which banned Chris Christie last year over his embrace of Barack Obama following super storm Sandy, just 29 per cent of the Nashua event's attendees said they identified with the 5-year-old right-wing tea party movement. Polling few enough votes to be lumped into the catch-all 'other' category was MSNBC morning show host and former congressman Joe Scarborough, whose presidential trial balloons have largely popped amid Republicans' concerns about his 2012 change of heart on gun control. Scarborough spoke Saturday morning and had little to show for it but a few book sales. Carson made big waves despite being nearly a continent away in Montana, speaking to a crowd of 1,300 at the Flathead County Fairgrounds in an event hosted by a Christian school. Kentucky Sen. Rand Paul (L) and New Jersey Gov. Chris Christie (R) placed #1 and #2 in the Northeast Republican Leadershpi Council straw poll, with a trip including Ben Carson nipping at their heels The results: Rand Paul and Christie on top, Ben Carson in a surprising tie for third, and Joe Scarborough nowhere to be found Red meat: Confernce attendees in New Hampshire were treated to a seemingly endless supply of political fire-stoking materials and anti-Obama one-liners 'I think the biggest issue facing us today is we've abandoned God,' he said there Friday night. 'I think the second biggest problem is we've become selfish. Nobody got that upset about [Operation] Fast and Furious. Nobody got that upset about Benghazi, NSA, IRS,' he went on, rattling off a series of President Barack Obama's most confidence-rattling scandals. 'But they got upset about Obamacare because that affected them personally.' Unconventional warfare: 2,000 hotel guests attending the CPAC convention this month received key cards featuring Carson's face and the draft-friendly 'Run Ben Run!' sogan In what sounded like the beginnings of a campaign speech, Carson directly attacked Democratic Party messaging. 'They say there's a war on women - give me a break! - racial wars, age wars, income wars, wherever they can drive a wedge into any crack,' Carson said. 'It's much easier to manipulate small groups than it is a whole population.' 'What is going to be necessary is we the people of the United States have to wake up and realize we are being manipulated and we are not each other's enemies. Those enemies are the people who are trying to manipulate us. We need to learn how to identify them. In cases where they are public officials we need to vote them out of office.' Vernon Robinson, campaign director with the National Draft Ben Carson for President Committee, told MailOnline that his pick 'is the only guy who can broaden the base of the GOP by getting a bunch more minority votes. ... he's the only guy who can heal the country.' Carson has become a lightning rod in the past year, beginning in early 2013 when he delivered health care-related remarks at a National Prayer Breakfast – with President Obama just feet away on the dais – that were openly hostile to the Obamacare program. At the prayer breakfast, Carson warned about the historical lessons of civilizations that 'destroyed themselves from within.' 'Moral decay. Fiscal irresponsibility. They destroyed themselves,' he said. 'And if you don't think that can happen to America, you get out your books and you start reading.' Partly because of that speech, Johns Hopkins University withdrew his invitation to speak at its 2013 commencement exercises. Carson is professor emeritus at the university's famed medical school. No mistaking it: The Republican Party has to respond to the Obama phenomenon by drafting a candidate who can boost GOP minority voting, says Carson 'draft' leader Vernon Robinson Robinson said Carson doesn't   coordinate messaging or scheduling with his organization. But as the   renowned surgeon's name gains national traction, he hasn't discouraged   the 'draft' movement either. The result, he said, is a maybe-candidacy with serious heft. 'He came out very close to where Chris Christie was, and the event was in his back yard, run by his guys,' Robinson explained. Matt Mowers, a former Christie campaign aide, is now executive director of the New Hampshire Republican State Committee, which put on the Nashua event. The poll of 223 attendees, which does not necessarily scientifically represent Republican voters, was conducted by WPA Opinion Research. Participants included 65-percent men. A separate 68 per cent were residents of New Hampshire, which will hold the nation's first presidential primary elections. 'What this survey tells is that is that no one candidate has really separated themselves from the potential field in 2016,' said WPA vice president Ryan Steusloff. 'At this point, the nomination is completely up-for-grabs and of the would-be contenders, no one can be ruled out just yet.' Enthusiasm: 'Run, Ben, Run!' mini-banners were available at CPAC and the New Hampshire event\n",
      "7192\n",
      "------------\n",
      "Carson, a conservative African-American neurosurgeon, isn't a candidate for any office. But a national 'draft committee' is raising money and trying to persuade him to run for the White House. Party favorites Rand Paul and Chris Christie ran #1 and #2 in modest straw poll held during the Northeast Republican Leadership Conference. Carson tied for third with Gov. Scott Walker and former Sen. Rick Santorum, less than 4 percentage points behind the leaders\n",
      "Sen. Rand Paul and Gov. Chris Christie placed first and second in a straw poll held during this weekend 's Northeast Republican Leadership Conference , but Dr. Ben Carson may have stolen the show without being a candidate for anything . He emerged in third place with 11 per cent support , tied with Wisconsin Gov. Scott Walker and former Sen. Rick Santorum . Paul led them by less than four points , with 14.7 per cent support . Christie polled 13 per cent . A ' draft committee ' intent on sparking Carson to run for the White House in 2016 raised more than $ 2.8 million in its first six months of existence . That 's more than double what the ' Ready For Hillary ' group raised in its initial half-year , even though Hillary Clinton 's candidacy seems far more assured than Carson 's . Dr. Ben Carson , professor emeritus at the Johns Hopkins School of Medicine , has become a quiet force in the 2016 Republican presidential race without announcing a thing The group angling to persuade Carson to make a White House run brought activists to support him at CPAC , near D.C. , in large numbers , but fared even better in a smaller New Hampshire setting without the extra muscle Why they fight : New England Republicans mocked their favorite Democratic villains during the two-day conference in Nashua , N.H. . The top two poll slots at the smallish event that concluded Saturday in Nashua , N.H. mirrored those of a statewide Suffolk University/Boston Herald poll released on March 6 . Christie and Paul were tied with 12 per cent support each in that earlier poll , a tiny level of backing that shows how wide open the 2016 GOP presidential nomination race is . The top vote-getter , in reality , was ' undecided . ' Clinton , by contrast , typically dominates the Democrats ' prospective 2016 field , leading all comers by 40 points or more . Carson was not included on the Suffolk pollsters ' list . He polled 9 per cent -- good enough for another third-place finish -- in a straw poll at this month 's Conservative Political Action Conference . But Paul dominated and won for the second straight year , with a 31 per cent showing . CPAC is a a much larger gathering dominated by insurgent tea party-aligned activists , which included remarks from Carson . But unlike the hyper-conservative event , which banned Chris Christie last year over his embrace of Barack Obama following super storm Sandy , just 29 per cent of the Nashua event 's attendees said they identified with the 5-year-old right-wing tea party movement . Polling few enough votes to be lumped into the catch-all ' other ' category was MSNBC morning show host and former congressman Joe Scarborough , whose presidential trial balloons have largely popped amid Republicans ' concerns about his 2012 change of heart on gun control . Scarborough spoke Saturday morning and had little to show for it but a few book sales . Carson made big waves despite being nearly a continent away in Montana , speaking to a crowd of 1,300 at the Flathead County Fairgrounds in an event hosted by a Christian school . Kentucky Sen. Rand Paul ( L ) and New Jersey Gov. Chris Christie ( R ) placed # 1 and # 2 in the Northeast Republican Leadershpi Council straw poll , with a trip including Ben Carson nipping at their heels The results : Rand Paul and Christie on top , Ben Carson in a surprising tie for third , and Joe Scarborough nowhere to be found Red meat : Confernce attendees in New Hampshire were treated to a seemingly endless supply of political fire-stoking materials and anti-Obama one-liners ' I think the biggest issue facing us today is we 've abandoned God , ' he said there Friday night . ' I think the second biggest problem is we 've become selfish . Nobody got that upset about [ Operation ] Fast and Furious . Nobody got that upset about Benghazi , NSA , IRS , ' he went on , rattling off a series of President Barack Obama 's most confidence-rattling scandals . ' But they got upset about Obamacare because that affected them personally . ' Unconventional warfare : 2,000 hotel guests attending the CPAC convention this month received key cards featuring Carson 's face and the draft-friendly ' Run Ben Run ! ' sogan In what sounded like the beginnings of a campaign speech , Carson directly attacked Democratic Party messaging . ' They say there 's a war on women - give me a break ! - racial wars , age wars , income wars , wherever they can drive a wedge into any crack , ' Carson said . ' It 's much easier to manipulate small groups than it is a whole population . ' ' What is going to be necessary is we the people of the United States have to wake up and realize we are being manipulated and we are not each other 's enemies . Those enemies are the people who are trying to manipulate us . We need to learn how to identify them . In cases where they are public officials we need to vote them out of office . ' Vernon Robinson , campaign director with the National Draft Ben Carson for President Committee , told MailOnline that his pick ' is the only guy who can broaden the base of the GOP by getting a bunch more minority votes . ... he 's the only guy who can heal the country . ' Carson has become a lightning rod in the past year , beginning in early 2013 when he delivered health care-related remarks at a National Prayer Breakfast -- with President Obama just feet away on the dais -- that were openly hostile to the Obamacare program . At the prayer breakfast , Carson warned about the historical lessons of civilizations that ' destroyed themselves from within . ' ' Moral decay . Fiscal irresponsibility . They destroyed themselves , ' he said . ' And if you do n't think that can happen to America , you get out your books and you start reading . ' Partly because of that speech , Johns Hopkins University withdrew his invitation to speak at its 2013 commencement exercises . Carson is professor emeritus at the university 's famed medical school . No mistaking it : The Republican Party has to respond to the Obama phenomenon by drafting a candidate who can boost GOP minority voting , says Carson ' draft ' leader Vernon Robinson Robinson said Carson does n't coordinate messaging or scheduling with his organization . But as the renowned surgeon 's name gains national traction , he has n't discouraged the ' draft ' movement either . The result , he said , is a maybe-candidacy with serious heft . ' He came out very close to where Chris Christie was , and the event was in his back yard , run by his guys , ' Robinson explained . Matt Mowers , a former Christie campaign aide , is now executive director of the New Hampshire Republican State Committee , which put on the Nashua event . The poll of 223 attendees , which does not necessarily scientifically represent Republican voters , was conducted by WPA Opinion Research . Participants included 65-percent men . A separate 68 per cent were residents of New Hampshire , which will hold the nation 's first presidential primary elections . ' What this survey tells is that is that no one candidate has really separated themselves from the potential field in 2016 , ' said WPA vice president Ryan Steusloff . ' At this point , the nomination is completely up-for-grabs and of the would-be contenders , no one can be ruled out just yet . ' Enthusiasm : ' Run , Ben , Run ! ' mini-banners were available at CPAC and the New Hampshire event\n"
     ]
    }
   ],
   "source": [
    "# import src text\n",
    "import json\n",
    "import re\n",
    "\n",
    "REMAP = {\"-lrb-\": \"(\", \"-rrb-\": \")\", \"-lcb-\": \"{\", \"-rcb-\": \"}\",\n",
    "         \"-lsb-\": \"[\", \"-rsb-\": \"]\", \"``\": '\"', \"''\": '\"',\"`\": \"'\",\n",
    "        \"-LRB-\": \"(\", \"-RRB-\": \")\", \"-LCB-\": \"{\", \"-RCB-\": \"}\",\n",
    "         \"-LSB-\": \"[\", \"-RSB-\": \"]\"}\n",
    "def clean(x):\n",
    "    return re.sub(\n",
    "        r\"-lrb-|-rrb-|-lcb-|-rcb-|-lsb-|-rsb-|-LRB-|-RRB-|-LCB-|-RCB-|-LSB-|-RSB-|``|''|`\",\n",
    "        lambda m: REMAP.get(m.group()), x)\n",
    "\n",
    "def load_json(p, lower):\n",
    "    source = []\n",
    "    tgt = []\n",
    "    flag = False\n",
    "    for sent in json.load(open(p))['sentences']:\n",
    "        tokens = [t['word'] for t in sent['tokens']]\n",
    "        if (lower):\n",
    "            tokens = [t.lower() for t in tokens]\n",
    "        if (tokens[0] == '@highlight'):\n",
    "            flag = True\n",
    "            tgt.append([])\n",
    "            continue\n",
    "        if (flag):\n",
    "            tgt[-1].extend(tokens)\n",
    "        else:\n",
    "            source.append(tokens)\n",
    "\n",
    "    source = [clean(' '.join(sent)).split() for sent in source]\n",
    "    tgt = [clean(' '.join(sent)).split() for sent in tgt]\n",
    "    return source, tgt\n",
    "sen_pool=[]\n",
    "with open('/home1/bqw/nlp_data/raw_stories/674321454616a451de284a9111cc8d14a92fb3be.story', 'r') as file:\n",
    "# with open('/home1/bqw/nlp_data/nyt_stories/124470.story', 'r') as file:\n",
    "\n",
    "    sen_pool=file.readlines()\n",
    "sen_pool=' '.join(sen_pool)\n",
    "doc_use=clean(sen_pool).replace('\\n \\n', '').replace('\\n',' ')\n",
    "\n",
    "temp=doc_use.split('@highlight')\n",
    "temp=[meta.strip() for meta in temp]\n",
    "src=temp[0]\n",
    "tgt='. '.join(temp[1:])\n",
    "print(src)\n",
    "print(len(src))\n",
    "print('------------')\n",
    "print(tgt)\n",
    "# src=\"Sen. Rand Paul and Gov. Chris Christie placed first and second in a straw poll held during this weekend's Northeast Republican Leadership Conference, but Dr. Ben Carson may have stolen the show without being a candidate for anything. He emerged in third place with 11 per cent support, tied with Wisconsin Gov. Scott Walker and former Sen. Rick Santorum. Paul led them by less than four points, with 14.7 per cent support. Christie polled 13 per cent. A 'draft committee' intent on sparking Carson to run for the White House in 2016 raised more than $2.8 million in its first six months of existence. That's more than double what the 'Ready For Hillary' group raised in its initial half-year, even though Hillary Clinton's candidacy seems far more assured than Carson's.\"\n",
    "# src=\"by sam webb a man who was jailed for torturing and murdering a father is now free to stay with his family - just a mile from the victim 's daughter . terence haddow , 68 , who killed kevin bruce in 2002 in edinburgh , has been given a first term release , which allows him out of prison for five days at a time . the victim 's daughter julie , 25 , who was 13 when her father died , said the news was a ` kick in the stomach ' . haddow and sturgeon were jailed for life with a minimum tariff of 14 years at the high court in edinburgh . julie bruce has spoken of her ordeal after it was revealed the killer of her father kevin , pictured with his daughter in 1988 , will be allowed out of prison for five days at a time mr bruce was beaten , had his cheeks slashed and his feet torn apart by a cheese grater by haddow and gordon sturgeon . the 38-year-old 's injuries were so severe pathologists doing the post-mortem lost count of the wounds , while a detective said they were the most horrific he had ever seen . they carried out the attack after a claim by haddow 's girlfriend , sharon mortimer , that mr bruce had molested her . during the three-day ordeal the attackers took mr bruce to get his benefits payments so they could buy alcohol . killer : terry haddow ( left ) in 2002 after he was sentenced to life in prison ms bruce , 25 , from edinburgh , told the daily record : ` my dad wo n't be able to give me away at my wedding , he wo n't meet his grandchildren and he will never be there for me because of the evil actions of these two men . ` he was in excruciating pain before he died , and now one of them is allowed to pop out of prison to see his family . ` it does n't seem fair . i feel the justice system has failed me . ' her parents split when she was 10 , but ms bruce would see her father , who she described as a ` kind , lovely man ' , every week . the administrator discovered that haddow would be allowed out of prison after signing the victim notification scheme . she now fears bumping into him in the street if he goes back to his last known address , just a mile from her home . ms bruce has also called for a change in the law so a life sentence actually means life in prison . a scottish prison service spokeswoman said : ` the granting of temporary release on licence conditions is an integral part of preparing long-term prisoners for returning to their communities and loved ones upon release . ` each individual who begins the process is subject to rigorous risk assessment at each stage of progression . ` any breach of licence immediately results in a return to closed conditions and a removal of community-based privileges . '\"\n",
    "\n",
    "a,b=load_json('/home1/bqw/nlp_data/cnn_token/674321454616a451de284a9111cc8d14a92fb3be.story.json',False)\n",
    "# a,b=load_json('/home1/bqw/nlp_data/nyt_token/10568.story.json',False)\n",
    "\n",
    "temp=[' '.join(meta) for meta in a]\n",
    "sen_pool=' '.join(temp)\n",
    "# doc_use=clean(sen_pool).replace('\\n \\n', '').replace('\\n',' ')\n",
    "\n",
    "# temp=doc_use.split('@highlight')\n",
    "# temp=[meta.strip() for meta in temp]\n",
    "# src=temp[0]\n",
    "# tgt='. '.join(temp[1:])\n",
    "# print(src)\n",
    "# print('------------')\n",
    "# print(tgt)\n",
    "src=sen_pool\n",
    "# print(src)\n",
    "# print(a)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------keyword extraction------------\n",
      "['poll', 'cent', '2016', 'event', 'attendees', 'straw', 'draft', 'presidential', 'wars', 'emeritus', 'manipulate', '#', 'candidate', 'polled', 'messaging', 'upset', 'enemies', 'nomination', 'smallish', 'dominated', 'support', 'minority', 'votes', 'comers', 'tea', 'dais', 'catch-all', 'half-year', 'included', 'activists', 'heft', 'nipping', 'tied', 'remarks', '14.7', 'irresponsibility', 'civilizations', 'one-liners', 'lumped', '223']\n"
     ]
    }
   ],
   "source": [
    "# keyword extraction\n",
    "use_src = src.split(' ')\n",
    "use_src = [i for i in use_src if i not in STOPWORDS]\n",
    "bow_vector = lda_dict.doc2bow(use_src)\n",
    "tfidf_vector = tfidf_dict[bow_vector]\n",
    "tfidf_vector.sort(key=lambda x: x[1], reverse=True)\n",
    "word_token_list = [word[0] for word in tfidf_vector]\n",
    "word_list = [lda_dict[token] for token in word_token_list]\n",
    "score_list = [score[1] for score in tfidf_vector]\n",
    "\n",
    "extract_ent = word_list[:40]\n",
    "print('-----------------keyword extraction------------')\n",
    "print(extract_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we 1\n"
     ]
    }
   ],
   "source": [
    "print('we',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------coreference---------------\n",
      "coref [[SEP]: [[SEP], [SEP], [SEP], [SEP], [SEP], [SEP], [SEP], [SEP], [SEP], [SEP], [SEP], [SEP], [SEP], [SEP]], a star: [a star, its, the star, the original star, its parent star], a star: [a star, its, the star, the original star], [CLS] ': [[CLS] ', [CLS] ', [CLS] '], a white dwarf star: [a white dwarf star, it], the edge of the milky way galaxy: [the edge of the milky way galaxy, the edge of the milky way galaxy], the milky way galaxy: [the milky way galaxy, the milky way galaxy], a planet: [a planet, the planet], [CLS]: [[CLS], [CLS]], a planet: [a planet, the planet], a planet: [a planet, its], such a planet: [such a planet, it], the white dwarf: [the white dwarf, the white dwarf], the planetary debris: [the planetary debris, it]]\n",
      "------------------entity---------------\n",
      "['cls', 'sep', 'one hundred ##th', '#', 'ten thousand', '##', '##- ##ray', 'first', '##bular', '##- ##ray ##', '##- ##']\n"
     ]
    }
   ],
   "source": [
    "## src chunk, ent, coreference\n",
    "src=\"[CLS] it may sound like the stuff of science fiction , but this stunning image shows that a white dwarf star ripped apart a planet as it came too close . [SEP] [CLS] astronomers say the unique event happened in an ancient cluster of stars at the edge of the milky way galaxy . [SEP] [CLS] a white dwarf star - the dense core of a star like the sun that has run out of nuclear fuel - may have ripped apart a planet as it came too close , they believe . [SEP] [CLS] nasa says a white dwarf star - the dense core of a star like the sun that has run out of nuclear fuel - ripped apart a planet at the edge of the milky way galaxy . [SEP] [CLS] when a star reaches its white dwarf stage , nearly all of the material from the star is packed inside a radius one hundred ##th that of the original star . [SEP] [CLS] this means that , for close encounters , the gravitational pull of the star and the associated tides , caused by the difference in gravity ' ##s pull on the near and far side of the planet , are greatly enhanced . [SEP] [CLS] for example , the gravity at the surface of a white dwarf is over ten thousand times higher than the gravity at the surface of the sun . [SEP] [CLS] using several telescopes , including nasa ' ##s chandra x ##- ##ray observatory , researchers have found evidence that a white dwarf star - the dense core of a star like the sun that has run out of nuclear fuel - may have ripped apart a planet as it came too close . [SEP] [CLS] when a star reaches its white dwarf stage , nearly all of the material from the star is packed inside a radius one hundred ##th that of the original star . [SEP] [CLS] this means that , for close encounters , the gravitational pull of the star and the associated tides , caused by the difference in gravity ' ##s pull on the near and far side of the planet , are greatly enhanced . [SEP] [CLS] for example , the gravity at the surface of a white dwarf is over ten thousand times higher than the gravity at the surface of the sun . [SEP] [CLS] ' a planet is first pulled away from its parent star by the gravity of the dense concentration of stars in a g ##lo ##bular cluster , ' the experts write . [SEP] [CLS] ' when such a planet passes too close to a white dwarf , it can be torn apart by the intense tidal forces of the white dwarf . [SEP] [CLS] ' the planetary debris is then heated and glow ##s in x ##- ##ray ##s as it falls onto the white dwarf . [SEP] [CLS] ' the observed amount of x ##- ##ray\".replace('<q>','. ')\n",
    "doc = nlp(src)\n",
    "src_coref=doc._.coref_clusters\n",
    "print('------------------coreference---------------')\n",
    "# print(len(src_coref[0]))\n",
    "src_coref=sorted(src_coref, key=lambda x: len(x),reverse=True)\n",
    "print('coref', src_coref)\n",
    "\n",
    "# print('------------------chunk---------------')\n",
    "# src_chunk=[]\n",
    "# for chunk in doc.noun_chunks:\n",
    "#     if chunk.text not in src_chunk:\n",
    "#         src_chunk.append(chunk.text)\n",
    "# print('chunk:',src_chunk)\n",
    "\n",
    "print('------------------entity---------------')\n",
    "src_ent=[]\n",
    "for ent in doc.ents:\n",
    "    cur = ent.text.lower()\n",
    "    if cur not in src_ent:\n",
    "        src_ent.append(ent.text.lower())\n",
    "#     print(ent, ent.label_, ent.label)\n",
    "print(src_ent)\n",
    "# print(src_ent[0].sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split \"_\"\n",
    "# temp=dict([('a_will',[3,4]),('b is',2)])\n",
    "# print(temp)\n",
    "# print(temp.items())\n",
    "neighbor_use=dict()\n",
    "for key, value in neighbor.items():\n",
    "    neighbor_use[' '.join(key.split('_'))]=value\n",
    "neighbor_key=neighbor_use.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Desires', 'destroy_united_states_of_america'],\n",
       " ['RelatedTo', 'figure'],\n",
       " ['RelatedTo', 'political'],\n",
       " ['RelatedTo', 'president'],\n",
       " ['RelatedTo', 'united_states_of_america'],\n",
       " ['RelatedTo', 'president'],\n",
       " ['RelatedTo', 'united_states_of_america'],\n",
       " ['RelatedTo', 'clan'],\n",
       " ['RelatedTo', 'feudal'],\n",
       " ['RelatedTo', 'fukui'],\n",
       " ['RelatedTo', 'japan'],\n",
       " ['RelatedTo', 'samurai'],\n",
       " ['Synonym', 'barack_hussein_obama']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor['obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------distant supervise ent------------------\n",
      "[('first', 48, 'second'), ('morning', 48, 'night')]\n"
     ]
    }
   ],
   "source": [
    "## distant supervise\n",
    "\n",
    "def have_relation(ent1,ent2):\n",
    "    if ent1 in neighbor_key:\n",
    "        po_list = neighbor_use[ent1]\n",
    "        for po in po_list:\n",
    "#             'Antonym',\n",
    "            if ' '.join(po[1].split('_')).lower() == ent2 and po[0] in ['Antonym','UsedFor', 'CapableOf', 'Causes', 'CausesDesire', 'Desires', 'ObstructedBy']:\n",
    "#             if ' '.join(po[1].split('_')).lower() == ent2:\n",
    "                return True\n",
    "    return False\n",
    "# 'UsedFor', 'CapableOf', 'Causes', 'CausesDesire', 'Desires', 'ObstructedBy'\n",
    "ent_spo = []\n",
    "for i in range(len(src_ent)):\n",
    "    for j in range(i+1, len(src_ent)):\n",
    "        s = src_ent[i]\n",
    "        o = src_ent[j]\n",
    "        if s and o not in STOPWORDS:\n",
    "            if have_relation(s, o) and s != o:\n",
    "                ent_spo.append((s, 48, o))\n",
    "print('----------------distant supervise ent------------------')\n",
    "print(ent_spo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 提取coref句间关系\n",
    "src_coref=[cluster for cluster in src_coref if cluster.main.text not in STOPWORDS]\n",
    "def in_the_same_sent(sent_sl1,sent_sl2):\n",
    "    return set(sent_sl1).intersection(set(sent_sl2))\n",
    "coref_sl=[]\n",
    "# print(len(src_coref))\n",
    "for cluster in src_coref:\n",
    "    cluster_sl=[]\n",
    "    for entity in cluster:\n",
    "        cluster_sl.append(entity.sent.start)\n",
    "    coref_sl.append(cluster_sl)\n",
    "coref_crosen_graph=[]\n",
    "crosen_rel_num=47\n",
    "for i in range(len(src_coref)):\n",
    "    for j in range(i+1, len(src_coref)):\n",
    "        a = src_coref[i]\n",
    "        b = src_coref[j]\n",
    "        a_sl = coref_sl[i]\n",
    "        b_sl = coref_sl[j]\n",
    "        if in_the_same_sent(a_sl, b_sl):\n",
    "            coref_crosen_graph.append((a.main.text.lower(), crosen_rel_num, b.main.text.lower()))\n",
    "print('--------------cross coref graph--------------')\n",
    "print(coref_crosen_graph)\n",
    "coref_graph=coref_crosen_graph\n",
    "print('jkkkkkjjjjjjjjjjjjjjjj')\n",
    "print(src_coref)\n",
    "print(coref_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Dr. Ben Carson', 'He', 'Paul', 'Carson', 'Ben Carson'], [\"Carson ' draft ' leader Vernon Robinson Robinson\", 'He', 'Robinson'], ['the White House', 'White House'], ['Paul'], [\"each other 's enemies\", 'Those enemies'], ['activists'], ['Scarborough', 'Joe Scarborough'], ['Democratic Party messaging', 'They'], ['Gov. Chris Christie', 'Christie'], ['11 per cent support , tied with Wisconsin Gov. Scott Walker and former Sen. Rick Santorum'], ['the 2016 Republican presidential race', 'the 2016 GOP presidential nomination race'], ['N.H.'], ['Christie and Paul', 'Chris Christie'], [\"the Nashua event 's attendees\"], ['Kentucky Sen. Rand Paul ( L ) and New Jersey Gov. Chris Christie ( R )'], ['God'], ['the United States', 'the country'], ['public officials'], ['MailOnline'], ['a National Prayer Breakfast', 'the prayer breakfast'], ['President Obama', 'Obama'], ['Johns Hopkins University'], ['New Hampshire'], ['no one candidate']]\n",
      "--------in coref graph--------------------\n",
      "[('dr. ben carson', 48, 'paul'), ('dr. ben carson', 48, 'carson'), ('dr. ben carson', 48, 'ben carson'), (\"carson ' draft ' leader vernon robinson robinson\", 48, 'robinson'), ('the white house', 48, 'white house'), (\"each other 's enemies\", 48, 'those enemies'), ('scarborough', 48, 'joe scarborough'), ('gov. chris christie', 48, 'christie'), ('the 2016 republican presidential race', 48, 'the 2016 gop presidential nomination race'), ('christie and paul', 48, 'chris christie'), ('the united states', 48, 'the country'), ('a national prayer breakfast', 48, 'the prayer breakfast'), ('president obama', 48, 'obama')]\n"
     ]
    }
   ],
   "source": [
    "## 提取coref cluster重要信息\n",
    "use_coref=[cluster.mentions for cluster in src_coref]\n",
    "new_clusters=[]\n",
    "for cluster in src_coref:\n",
    "    mentions_list=cluster.mentions\n",
    "    new_mentions=[]\n",
    "    for mention in mentions_list:\n",
    "        if mention.text not in STOPWORDS and mention.text not in new_mentions:\n",
    "            new_mentions.append(mention.text)\n",
    "    new_clusters.append(new_mentions)\n",
    "print(new_clusters)\n",
    "\n",
    "coref_insen_graph=[]\n",
    "insen_rel_num=48\n",
    "for cluster in new_clusters:\n",
    "    a=cluster[0].lower()\n",
    "    for i in range(1,len(cluster)):\n",
    "        b=cluster[i].lower()\n",
    "        if b not in STOPWORDS:\n",
    "            coref_insen_graph.append((a, insen_rel_num, b))\n",
    "print('--------in coref graph--------------------')\n",
    "print(coref_insen_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'nash', '##ua', 'event', \"'\", '##s', 'attendees']\n",
      "[24185, 1010, 2097, 2600, 1012]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[unused19]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.tokenize(\"the nashua event 's attendees\"))\n",
    "print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('wo , will rock .')))\n",
    "tokenizer.convert_ids_to_tokens([20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dr. ben carson': 23, \"carson ' draft ' leader vernon robinson robinson\": 8, 'the white house': 4, 'paul': 4, \"each other 's enemies\": 4, 'activists': 3, 'scarborough': 3, 'democratic party messaging': 3, 'gov. chris christie': 2, '11 per cent support , tied with wisconsin gov. scott walker and former sen. rick santorum': 2, 'the 2016 republican presidential race': 2, 'n.h.': 2, 'christie and paul': 2, \"the nashua event 's attendees\": 2, 'kentucky sen. rand paul ( l ) and new jersey gov. chris christie ( r )': 2, 'god': 2, 'the united states': 2, 'public officials': 2, 'mailonline': 2, 'a national prayer breakfast': 2, 'president obama': 2, 'johns hopkins university': 2, 'new hampshire': 2, 'no one candidate': 2}\n",
      "('dr. ben carson', 47, \"carson ' draft ' leader vernon robinson robinson\")\n",
      "('dr. ben carson', 47, 'the white house')\n",
      "('dr. ben carson', 47, 'activists')\n",
      "('dr. ben carson', 47, 'scarborough')\n",
      "('dr. ben carson', 47, 'democratic party messaging')\n",
      "('dr. ben carson', 47, 'gov. chris christie')\n",
      "('dr. ben carson', 47, '11 per cent support , tied with wisconsin gov. scott walker and former sen. rick santorum')\n",
      "('dr. ben carson', 47, 'the 2016 republican presidential race')\n",
      "('dr. ben carson', 47, 'n.h.')\n",
      "('dr. ben carson', 47, 'kentucky sen. rand paul ( l ) and new jersey gov. chris christie ( r )')\n",
      "('dr. ben carson', 47, 'a national prayer breakfast')\n",
      "('dr. ben carson', 47, 'president obama')\n",
      "(\"carson ' draft ' leader vernon robinson robinson\", 47, 'president obama')\n",
      "('the white house', 47, 'activists')\n",
      "('the white house', 47, 'the 2016 republican presidential race')\n",
      "('the white house', 47, 'n.h.')\n",
      "('paul', 47, 'the 2016 republican presidential race')\n",
      "('paul', 47, 'christie and paul')\n",
      "('paul', 47, \"the nashua event 's attendees\")\n",
      "(\"each other 's enemies\", 47, 'the united states')\n",
      "(\"each other 's enemies\", 47, 'public officials')\n",
      "('activists', 47, 'the 2016 republican presidential race')\n",
      "('activists', 47, 'n.h.')\n",
      "('the 2016 republican presidential race', 47, 'n.h.')\n",
      "('the 2016 republican presidential race', 47, 'christie and paul')\n",
      "('christie and paul', 47, \"the nashua event 's attendees\")\n",
      "-----tokenized spo list-------------\n",
      "[([2852, 29625, 3841, 9806], 47, [9806, 1005, 4433, 1005, 3003, 11447, 6157, 6157]), ([2852, 29625, 3841, 9806], 47, [1996, 2317, 2160]), ([2852, 29625, 3841, 9806], 47, [10134]), ([2852, 29625, 3841, 9806], 47, [18603]), ([2852, 29625, 3841, 9806], 47, [3537, 2283, 24732]), ([2852, 29625, 3841, 9806], 47, [18079, 29625, 3782, 13144]), ([2852, 29625, 3841, 9806], 47, [2340, 2566, 9358, 2490, 1010, 5079, 2007, 5273, 18079, 29625, 3660, 5232, 1998, 2280, 12411, 29625, 6174, 11685, 6824]), ([2852, 29625, 3841, 9806], 47, [1996, 2355, 3951, 4883, 2679]), ([2852, 29625, 3841, 9806], 47, [1050, 29625, 2232, 29625]), ([2852, 29625, 3841, 9806], 47, [5612, 12411, 29625, 14566, 2703, 1006, 1048, 1007, 1998, 2047, 3933, 18079, 29625, 3782, 13144, 1006, 1054, 1007]), ([2852, 29625, 3841, 9806], 47, [1037, 2120, 7083, 6350]), ([2852, 29625, 3841, 9806], 47, [2343, 8112]), ([9806, 1005, 4433, 1005, 3003, 11447, 6157, 6157], 47, [2343, 8112]), ([1996, 2317, 2160], 47, [10134]), ([1996, 2317, 2160], 47, [1996, 2355, 3951, 4883, 2679]), ([1996, 2317, 2160], 47, [1050, 29625, 2232, 29625]), ([2703], 47, [1996, 2355, 3951, 4883, 2679]), ([2703], 47, [13144, 1998, 2703]), ([2703], 47, [1996, 10594, 6692, 2724, 1005, 2015, 19973]), ([2169, 2060, 1005, 2015, 6716], 47, [1996, 2142, 2163]), ([2169, 2060, 1005, 2015, 6716], 47, [2270, 4584]), ([10134], 47, [1996, 2355, 3951, 4883, 2679]), ([10134], 47, [1050, 29625, 2232, 29625]), ([1996, 2355, 3951, 4883, 2679], 47, [1050, 29625, 2232, 29625]), ([1996, 2355, 3951, 4883, 2679], 47, [13144, 1998, 2703]), ([13144, 1998, 2703], 47, [1996, 10594, 6692, 2724, 1005, 2015, 19973])]\n",
      "jjjjjjjjjjjj\n",
      "[[2852, 29625, 3841, 9806], [9806, 1005, 4433, 1005, 3003, 11447, 6157, 6157], [1996, 2317, 2160], [10134], [18603], [3537, 2283, 24732], [18079, 29625, 3782, 13144], [2340, 2566, 9358, 2490, 1010, 5079, 2007, 5273, 18079, 29625, 3660, 5232, 1998, 2280, 12411, 29625, 6174, 11685, 6824], [1996, 2355, 3951, 4883, 2679], [1050, 29625, 2232, 29625], [5612, 12411, 29625, 14566, 2703, 1006, 1048, 1007, 1998, 2047, 3933, 18079, 29625, 3782, 13144, 1006, 1054, 1007], [1037, 2120, 7083, 6350], [2343, 8112], [2703], [13144, 1998, 2703], [1996, 10594, 6692, 2724, 1005, 2015, 19973], [2169, 2060, 1005, 2015, 6716], [1996, 2142, 2163], [2270, 4584]]\n",
      "[23, 8, 4, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2]\n",
      "[2852, 29625, 3841, 9806]\n",
      "['dr', '##.', 'ben', 'carson']\n"
     ]
    }
   ],
   "source": [
    "# tokenize to spo list and save\n",
    "salient_dict=dict()\n",
    "for cluster in src_coref:\n",
    "    salient_dict[cluster.main.text.lower()]=len(cluster)\n",
    "print(salient_dict)\n",
    "\n",
    "\n",
    "spo_list = []\n",
    "for spo in coref_graph:\n",
    "    print(spo)\n",
    "    s = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(spo[0]))\n",
    "    o = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(spo[2]))\n",
    "    spo_list.append((s, 47, o))\n",
    "    \n",
    "spo_list = []\n",
    "ent_list = []\n",
    "rel_list = []\n",
    "score_list = []\n",
    "for spo in coref_graph:\n",
    "    #\n",
    "    salient_s=salient_dict[spo[0]]\n",
    "    salient_o=salient_dict[spo[2]]\n",
    "    #\n",
    "    s = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(spo[0]))\n",
    "    if s not in ent_list:\n",
    "        ent_list.append(s)\n",
    "        score_list.append(salient_s)\n",
    "    o = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(spo[2]))\n",
    "    if o not in ent_list:\n",
    "        ent_list.append(o)\n",
    "        score_list.append(salient_o)\n",
    "    spo_list.append((s, crosen_rel_num, o))\n",
    "print('-----tokenized spo list-------------')\n",
    "print(spo_list)\n",
    "print('jjjjjjjjjjjj')\n",
    "print(ent_list)\n",
    "print(score_list)\n",
    "print(ent_list[0])\n",
    "print(tokenizer.convert_ids_to_tokens(ent_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text']\n"
     ]
    }
   ],
   "source": [
    "' '.join(['dr', '##.', 'ben', 'carson']).replace(' ##','')\n",
    "a=[]\n",
    "a.append('text')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n",
      "torch.Size([2, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "ent_embedding=torch.ones((2,5,10))\n",
    "position_embedding=nn.Embedding(10,10)\n",
    "position_ids = torch.arange(ent_embedding.size()[1], dtype=torch.long, device=ent_embedding.device)\n",
    "position_ids = position_ids.unsqueeze(0).expand((ent_embedding.size(0),ent_embedding.size(1)))\n",
    "position_emb=position_embedding(position_ids)\n",
    "print(position_ids)\n",
    "print(position_emb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import linecache\n",
    "import codecs\n",
    "\n",
    "data = pd.read_table(\"/home1/bqw/GraphSum/test_ent_1_step112000.ent\", sep=\"\\[ANA\\]\", header=None, names=['gold','cand_our', 'cand_bertsum','ent','ent_num','spo_num'],\n",
    "                     encoding='utf-8', engine='python')\n",
    "# data = pd.read_table(\"/home1/bqw/GraphSum/test_ent_1_step112000.ent\", sep=\"\\[ANA\\]\", header=None, names=['gold','cand','ent'],\n",
    "#                      encoding='utf-8', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>cand_our</th>\n",
       "      <th>cand_bertsum</th>\n",
       "      <th>ent</th>\n",
       "      <th>ent_num</th>\n",
       "      <th>spo_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>students spend $ 1,000 a year on prom on avera...</td>\n",
       "      <td>students this year will likely spend of a thir...</td>\n",
       "      <td>the first trailer for the upcoming biopic on t...</td>\n",
       "      <td>[root][CLS]matthew ho from toronto[CLS]his stu...</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tristan da cunha holds competition for archite...</td>\n",
       "      <td>tristan da cunha is the most isolated human se...</td>\n",
       "      <td>students this year will likely spend of a thir...</td>\n",
       "      <td>[root][CLS]tristan[CLS]mitcham[CLS]the islande...</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                gold  \\\n",
       "0  students spend $ 1,000 a year on prom on avera...   \n",
       "1  tristan da cunha holds competition for archite...   \n",
       "\n",
       "                                            cand_our  \\\n",
       "0  students this year will likely spend of a thir...   \n",
       "1  tristan da cunha is the most isolated human se...   \n",
       "\n",
       "                                        cand_bertsum  \\\n",
       "0  the first trailer for the upcoming biopic on t...   \n",
       "1  students this year will likely spend of a thir...   \n",
       "\n",
       "                                                 ent  ent_num  spo_num  \n",
       "0  [root][CLS]matthew ho from toronto[CLS]his stu...       20       36  \n",
       "1  [root][CLS]tristan[CLS]mitcham[CLS]the islande...       13       21  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>cand_our</th>\n",
       "      <th>cand_bertsum</th>\n",
       "      <th>ent</th>\n",
       "      <th>ent_num</th>\n",
       "      <th>spo_num</th>\n",
       "      <th>gold_ent</th>\n",
       "      <th>cand_out_ent</th>\n",
       "      <th>cand_bert_ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>students spend $ 1,000 a year on prom on avera...</td>\n",
       "      <td>students this year will likely spend of a thir...</td>\n",
       "      <td>the first trailer for the upcoming biopic on t...</td>\n",
       "      <td>[root][CLS]matthew ho from toronto[CLS]his stu...</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                gold  \\\n",
       "0  students spend $ 1,000 a year on prom on avera...   \n",
       "\n",
       "                                            cand_our  \\\n",
       "0  students this year will likely spend of a thir...   \n",
       "\n",
       "                                        cand_bertsum  \\\n",
       "0  the first trailer for the upcoming biopic on t...   \n",
       "\n",
       "                                                 ent  ent_num  spo_num  \\\n",
       "0  [root][CLS]matthew ho from toronto[CLS]his stu...       20       36   \n",
       "\n",
       "   gold_ent  cand_out_ent  cand_bert_ent  \n",
       "0         1             7              0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_ent(src, ent):\n",
    "    ent_list=ent.split('[CLS]')\n",
    "    count = 0\n",
    "    for meta in ent_list:\n",
    "        if meta in src:\n",
    "            count += 1\n",
    "    return count\n",
    "    \n",
    "data['gold_ent'] = data.apply(lambda x: has_ent(x['gold'], x['ent']), axis=1)\n",
    "data['cand_out_ent'] = data.apply(lambda x: has_ent(x['cand_our'], x['ent']), axis=1)\n",
    "data['cand_bert_ent'] = data.apply(lambda x: has_ent(x['cand_bertsum'], x['ent']), axis=1)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_num</th>\n",
       "      <th>spo_num</th>\n",
       "      <th>gold_ent</th>\n",
       "      <th>cand_out_ent</th>\n",
       "      <th>cand_bert_ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11490.000000</td>\n",
       "      <td>11490.000000</td>\n",
       "      <td>11490.000000</td>\n",
       "      <td>11490.000000</td>\n",
       "      <td>11490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.824195</td>\n",
       "      <td>25.948042</td>\n",
       "      <td>3.236902</td>\n",
       "      <td>3.992428</td>\n",
       "      <td>0.211227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.641438</td>\n",
       "      <td>20.266546</td>\n",
       "      <td>2.178699</td>\n",
       "      <td>2.352635</td>\n",
       "      <td>0.506581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ent_num       spo_num      gold_ent  cand_out_ent  cand_bert_ent\n",
       "count  11490.000000  11490.000000  11490.000000  11490.000000   11490.000000\n",
       "mean      14.824195     25.948042      3.236902      3.992428       0.211227\n",
       "std        7.641438     20.266546      2.178699      2.352635       0.506581\n",
       "min        1.000000      1.000000      0.000000      0.000000       0.000000\n",
       "25%        9.000000     12.000000      2.000000      2.000000       0.000000\n",
       "50%       13.000000     21.000000      3.000000      4.000000       0.000000\n",
       "75%       19.000000     34.000000      4.000000      5.000000       0.000000\n",
       "max       68.000000    224.000000     17.000000     16.000000       9.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3622\n",
      "5338\n",
      "2530\n"
     ]
    }
   ],
   "source": [
    "low_group = data[(data.ent_num<=10)].index.tolist()\n",
    "medium_group = data[(data.ent_num>10) & (data.ent_num<20)].index.tolist()\n",
    "high_group = data[(data.ent_num>=20)].index.tolist()\n",
    "print(len(low_group))\n",
    "print(len(medium_group))\n",
    "print(len(high_group))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_results_to_str(results_dict):\n",
    "    return \">> ROUGE-F(1/2/3/l): {:.2f}/{:.2f}/{:.2f}\\nROUGE-R(1/2/3/l): {:.2f}/{:.2f}/{:.2f}\\n\".format(\n",
    "        results_dict[\"rouge_1_f_score\"] * 100,\n",
    "        results_dict[\"rouge_2_f_score\"] * 100,\n",
    "        # results_dict[\"rouge_3_f_score\"] * 100,\n",
    "        results_dict[\"rouge_l_f_score\"] * 100,\n",
    "        results_dict[\"rouge_1_recall\"] * 100,\n",
    "        results_dict[\"rouge_2_recall\"] * 100,\n",
    "        # results_dict[\"rouge_3_f_score\"] * 100,\n",
    "        results_dict[\"rouge_l_recall\"] * 100\n",
    "\n",
    "        # ,results_dict[\"rouge_su*_f_score\"] * 100\n",
    "    )\n",
    "\n",
    "def test_rouge(temp_dir, cand, ref):\n",
    "    candidates = [line.strip() for line in open(cand, encoding='utf-8')]\n",
    "    references = [line.strip() for line in open(ref, encoding='utf-8')]\n",
    "    print(len(candidates))\n",
    "    print(len(references))\n",
    "    assert len(candidates) == len(references)\n",
    "\n",
    "    cnt = len(candidates)\n",
    "    current_time = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())\n",
    "    tmp_dir = os.path.join(temp_dir, \"rouge-tmp-{}\".format(current_time))\n",
    "    if not os.path.isdir(tmp_dir):\n",
    "        os.mkdir(tmp_dir)\n",
    "        os.mkdir(tmp_dir + \"/candidate\")\n",
    "        os.mkdir(tmp_dir + \"/reference\")\n",
    "    try:\n",
    "\n",
    "        for i in range(cnt):\n",
    "            if len(references[i]) < 1:\n",
    "                continue\n",
    "            with open(tmp_dir + \"/candidate/cand.{}.txt\".format(i), \"w\",\n",
    "                      encoding=\"utf-8\") as f:\n",
    "                f.write(candidates[i])\n",
    "            with open(tmp_dir + \"/reference/ref.{}.txt\".format(i), \"w\",\n",
    "                      encoding=\"utf-8\") as f:\n",
    "                f.write(references[i])\n",
    "        r = pyrouge.Rouge155(temp_dir=temp_dir)\n",
    "        r.model_dir = tmp_dir + \"/reference/\"\n",
    "        r.system_dir = tmp_dir + \"/candidate/\"\n",
    "        r.model_filename_pattern = 'ref.#ID#.txt'\n",
    "        r.system_filename_pattern = r'cand.(\\d+).txt'\n",
    "        rouge_results = r.convert_and_evaluate()\n",
    "        print(rouge_results)\n",
    "        results_dict = r.output_to_dict(rouge_results)\n",
    "    finally:\n",
    "        pass\n",
    "        if os.path.isdir(tmp_dir):\n",
    "            shutil.rmtree(tmp_dir)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------graph------- -------\n",
      "[['candidate', 'RelatedTo', 'presidential'], ['polled', 'FormOf', 'poll'], ['polled', 'RelatedTo', 'poll']]\n",
      "['candidate', 'presidential', 'polled', 'poll']\n"
     ]
    }
   ],
   "source": [
    "# graph extraction\n",
    "subject_list = list(neighbor.keys())\n",
    "# print(neighbor['Ben Carson'])\n",
    "\n",
    "# print(subject_list[:10])\n",
    "spo = []\n",
    "ent_list = []\n",
    "rel_list = []\n",
    "show_spo = []\n",
    "show_ent = []\n",
    "for subject in extract_ent:\n",
    "    if subject in subject_list:\n",
    "        sub_list = neighbor[subject]\n",
    "        for ob in sub_list:\n",
    "            ent=ob[1]\n",
    "            # 0.4\n",
    "            if ent in extract_ent:\n",
    "                spo_meta = [subject, ob[0], ent]\n",
    "\n",
    "                if spo_meta not in spo and subject != ent:\n",
    "                    show_spo.append(spo_meta)\n",
    "                    if spo_meta[0] not in show_ent:\n",
    "                        show_ent.append(spo_meta[0])\n",
    "                    if spo_meta[2] not in show_ent:\n",
    "                        show_ent.append(spo_meta[2])\n",
    "                    new = [tokenizer.convert_tokens_to_ids([spo_meta[0]])[0], rel_map[spo_meta[1]],\n",
    "                           tokenizer.convert_tokens_to_ids([spo_meta[2]])[0]]\n",
    "                    spo_meta = new\n",
    "                    spo.append(spo_meta)\n",
    "                    if spo_meta[0] not in ent_list:\n",
    "                        ent_list.append(spo_meta[0])\n",
    "                    if spo_meta[2] not in ent_list:\n",
    "                        ent_list.append(spo_meta[2])\n",
    "                    if spo_meta[1] not in rel_list:\n",
    "                        rel_list.append(spo_meta[1])\n",
    "print('--------------graph------- -------')          \n",
    "# print(ent_list)\n",
    "# print(rel_list)\n",
    "# print(spo)\n",
    "print(show_spo)\n",
    "print(show_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coref [ms: [ms, her, she]]\n",
      "jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\n",
      "chunk: [\"julie bruce 's father kevin\", 'death', 'killer terence haddow', 'life', 'prison', 'ms', 'her fear', 'haddow', 'the street', 'she', 'justice system']\n",
      "jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\n",
      "[2002, 68]\n"
     ]
    }
   ],
   "source": [
    "tgt=\"julie bruce 's father kevin was tortured to death in 2002<q>killer terence haddow , 68 , received life but will be allowed out of prison<q>ms bruce has spoken of her fear at bumping into haddow in the street<q>the 25-year-old says she feels let down by justice system\".replace('<q>',' . ')\n",
    "\n",
    "doc = nlp(tgt)\n",
    "\n",
    "tgt_coref=doc._.coref_clusters\n",
    "print('coref', tgt_coref)\n",
    "print('jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj')\n",
    "\n",
    "tgt_chunk=[]\n",
    "for chunk in doc.noun_chunks:\n",
    "    if chunk.text not in tgt_chunk:\n",
    "        tgt_chunk.append(chunk.text)\n",
    "print('chunk:',tgt_chunk)\n",
    "print('jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj')\n",
    "\n",
    "\n",
    "tgt_ent=[]\n",
    "for ent in doc.ents:\n",
    "    tgt_ent.append(ent)\n",
    "#     print(ent, ent.label_, ent.label)\n",
    "print(tgt_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "word_list = src_chunk\n",
    "filtered_words = [word for word in word_list if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coref [Gov. Chris Christie: [Gov. Chris Christie, Christie], Dr. Ben Carson: [Dr. Ben Carson, He, Paul, Carson, Carson], 11 per cent support , tied with Wisconsin Gov. Scott Walker and former Sen. Rick Santorum: [11 per cent support , tied with Wisconsin Gov. Scott Walker and former Sen. Rick Santorum, them], the White House: [the White House, its, its]]\n",
      "jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\n",
      "chunk: ['Sen. Rand Paul', 'Gov. Chris Christie', 'a straw poll', \"this weekend 's Northeast Republican Leadership Conference\", 'Dr. Ben Carson', 'the show', 'a candidate', 'anything', 'He', 'third place', 'cent', 'Wisconsin Gov. Scott Walker', 'former Sen. Rick Santorum', 'Paul', 'them', 'less than four points', 'cent support', 'Christie', \"A ` draft committee ' intent\", 'Carson', 'the White House', 'its first six months', 'existence', \"Hillary ' group\", 'its initial half-year', \"Hillary Clinton 's candidacy\"]\n",
      "jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\n",
      "[Rand Paul, Chris Christie, first, second, weekend, Northeast Republican Leadership Conference, Ben Carson, third, 11, Wisconsin, Scott Walker, Rick Santorum, Paul, less than four, 14.7 per cent, 13 per cent, Carson, the White House, 2016, more than $ 2.8 million, its first six months, half-year, Hillary Clinton 's, Carson]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"displaCy uses CSS and JavaScript to show you how computers \"\n",
    "    \"understand language\")\n",
    "\n",
    "doc=nlp(\"Julie Bruce's father kevin was tortured to death in 2002. Killer terence haddow, 68, received life but will be allowed out of prison. Ms bruce has spoken of her fear at bumping into haddow in the street. The 25-year-old says she feels let down by justice system\"\n",
    ")\n",
    "doc=nlp(\"Sen. Rand Paul and Gov. Chris Christie placed first and second in a straw poll held during this weekend 's Northeast Republican Leadership Conference , but Dr. Ben Carson may have stolen the show without being a candidate for anything . He emerged in third place with 11 per cent support , tied with Wisconsin Gov. Scott Walker and former Sen. Rick Santorum . Paul led them by less than four points , with 14.7 per cent support . Christie polled 13 per cent . A ` draft committee ' intent on sparking Carson to run for the White House in 2016 raised more than $ 2.8 million in its first six months of existence . That 's more than double what the ` Ready For Hillary ' group raised in its initial half-year , even though Hillary Clinton 's candidacy seems far more assured than Carson 's .\")\n",
    "# doc=nlp(\"Sen. Rand Paul and Gov. Chris Christie placed first and second in a straw poll held during this weekend's Northeast Republican Leadership Conference, but Dr. Ben Carson may have stolen the show without being a candidate for anything. He emerged in third place with 11 per cent support, tied with Wisconsin Gov. Scott Walker and former Sen. Rick Santorum. Paul led them by less than four points, with 14.7 per cent support. Christie polled 13 per cent. A 'draft committee' intent on sparking Carson to run for the White House in 2016 raised more than $2.8 million in its first six months of existence. That's more than double what the 'Ready For Hillary' group raised in its initial half-year, even though Hillary Clinton's candidacy seems far more assured than Carson's.\")\n",
    "tgt_coref=doc._.coref_clusters\n",
    "print('coref', tgt_coref)\n",
    "print('jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj')\n",
    "\n",
    "tgt_chunk=[]\n",
    "for chunk in doc.noun_chunks:\n",
    "    if chunk.text not in tgt_chunk:\n",
    "        tgt_chunk.append(chunk.text)\n",
    "print('chunk:',tgt_chunk)\n",
    "print('jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj')\n",
    "\n",
    "tgt_ent=[]\n",
    "for ent in doc.ents:\n",
    "    tgt_ent.append(ent)\n",
    "#     print(ent, ent.label_, ent.label)\n",
    "print(tgt_ent)\n",
    "\n",
    "# for word in doc:\n",
    "#     if word.dep_ in (\"xcomp\", \"ccomp\"):\n",
    "#         print(word)\n",
    "#         print(\"\".join(w.text_with_ws for w in word.subtree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uses\n",
      "displaCy\n",
      "language\n",
      "[displaCy, uses, CSS, and, JavaScript, to, show, you, how, computers, understand, language]\n",
      "ROOT\n",
      "jjjjjjjjjjjjjjj\n",
      "displaCy uses\n",
      "CSS\n",
      "JavaScript\n",
      "you\n",
      "computers\n",
      "language\n"
     ]
    }
   ],
   "source": [
    "print(doc[1].head)\n",
    "print(doc[1].left_edge)\n",
    "print(doc[1].right_edge)\n",
    "print(list(doc[1].subtree))\n",
    "print(doc[1].dep_)\n",
    "print('jjjjjjjjjjjjjjj')\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sen. Rand Paul and Gov. Chris Christie placed first and second in a straw poll held during this weekend's Northeast Republican Leadership Conference, but Dr. Ben Carson may have stolen the show without being a candidate for anything. He emerged in third place with 11 per cent support, tied with Wisconsin Gov. Scott Walker and former Sen. Rick Santorum. Paul led them by less than four points, with 14.7 per cent support. Christie polled 13 per cent. A 'draft committee' intent on sparking Carson to run for the White House in 2016 raised more than $2.8 million in its first six months of existence. That's more than double what the 'Ready For Hillary' group raised in its initial half-year, even though Hillary Clinton's candidacy seems far more assured than Carson's.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he hasn't discouraged \n",
      "the 'draft' \n"
     ]
    }
   ],
   "source": [
    "# displacy.render(doc, style='dep',jupyter=True)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[displaCy uses, CSS, JavaScript, you, computers, language]\n",
      "CSS\n",
      "JavaScript\n"
     ]
    }
   ],
   "source": [
    "def filter_spans(spans):\n",
    "    # Filter a sequence of spans so they don't contain overlaps\n",
    "    # For spaCy 2.1.4+: this function is available as spacy.util.filter_spans()\n",
    "    get_sort_key = lambda span: (span.end - span.start, -span.start)\n",
    "    sorted_spans = sorted(spans, key=get_sort_key, reverse=True)\n",
    "    result = []\n",
    "    seen_tokens = set()\n",
    "    for span in sorted_spans:\n",
    "        # Check for end - 1 here because boundaries are inclusive\n",
    "        if span.start not in seen_tokens and span.end - 1 not in seen_tokens:\n",
    "            result.append(span)\n",
    "        seen_tokens.update(range(span.start, span.end))\n",
    "    result = sorted(result, key=lambda span: span.start)\n",
    "    return result\n",
    "\n",
    "\n",
    "spans = list(doc.ents) + list(doc.noun_chunks)\n",
    "spans = filter_spans(spans)\n",
    "print(spans)\n",
    "with doc.retokenize() as retokenizer:\n",
    "    for span in spans:\n",
    "        retokenizer.merge(span)\n",
    "# print(spans)\n",
    "for ent in doc.ents:\n",
    "    print(ent,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
